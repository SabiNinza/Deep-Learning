{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import cv2\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import json\n",
    "from time import time\n",
    "import pickle\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_Cap_map = None\n",
    "with open(\"img_Cap_map.txt\") as f:\n",
    "    img_Cap_map = f.read()\n",
    "    \n",
    "json_accept_str = img_Cap_map.replace(\"'\",\"\\\"\")\n",
    "img_Cap_map = json.loads(json_accept_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(img_Cap_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size :: 8424\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "for k in img_Cap_map.keys():\n",
    "    [vocab.update(s.split()) for s in img_Cap_map[k]]\n",
    "print(\"vocab size :: %d\"%len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total word size :: 373837\n"
     ]
    }
   ],
   "source": [
    "total_wrd = list()\n",
    "for k in img_Cap_map.keys():\n",
    "    [total_wrd.append(i) for s in img_Cap_map[k] for i in s.split()]\n",
    "print(\"total word size :: %d\"%len(total_wrd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = collections.Counter(total_wrd)\n",
    "freq_cnt = dict(counter)\n",
    "sorted_freq_cnt = sorted(freq_cnt.items(),reverse = True,key = lambda x:x[1])\n",
    "threshold = 10\n",
    "sorted_freq_cnt = [x for x in sorted_freq_cnt if x[1]>threshold]\n",
    "total_wrd = [x[0] for x in sorted_freq_cnt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(total_wrd))\n",
    "# print(len(freq_cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Data Preparatioin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?pip3 install import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from Data_cleaning_and_collection import readTxtFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = readTxtFile(\"Flickr8k_text/Flickr_8k.trainImages.txt\")\n",
    "test_data = readTxtFile(\"Flickr8k_text/Flickr_8k.testImages.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [row.split(\".\")[0] for row in train_data.split(\"\\n\")[:-1]]\n",
    "test = [row.split(\".\")[0] for row in test_data.split(\"\\n\")[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_cap_map = {}\n",
    "\n",
    "for img_id in train:\n",
    "    train_img_cap_map[img_id] = list()\n",
    "    for cap in img_Cap_map[img_id]:\n",
    "        cap_to_append  = \"ss \" + cap + \" es\"\n",
    "        train_img_cap_map[img_id].append(cap_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_img_cap_map[\"1000268201_693b08cb0e\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_img_cap_map.txt\",\"w\") as f:\n",
    "    f.write(str(train_img_cap_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
