{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## age or gender through caffe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping \n",
    "\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "age_list = ['(0, 2)', '(4, 6)', '(8, 12)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\n",
    "gender_list = ['Male', 'Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_caffe_models():\n",
    "\t\n",
    "\tage_net = cv2.dnn.readNetFromCaffe(\n",
    "\t\t'data/deploy_age.prototxt', \n",
    "\t\t'data/age_net.caffemodel')\n",
    "\n",
    "\tgender_net = cv2.dnn.readNetFromCaffe(\n",
    "\t\t'data/deploy_gender.prototxt', \n",
    "\t\t'data/gender_net.caffemodel')\n",
    "\n",
    "\treturn(age_net, gender_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_gender_of_face(age_net,gender_net,file):\n",
    "    # Get Face \n",
    "    face_img = cv2.imread(file,cv2.IMREAD_COLOR)\n",
    "#     plt.imshow(face_img)\n",
    "    blob = cv2.dnn.blobFromImage(face_img, 1, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "\n",
    "    #Predict Gender\n",
    "    gender_net.setInput(blob)\n",
    "    gender_preds = gender_net.forward()\n",
    "    gender = gender_preds[0].argmax()\n",
    "#     print(\"Gender : \" + gender)\n",
    "\n",
    "    #Predict Age\n",
    "    age_net.setInput(blob)\n",
    "    age_preds = age_net.forward()\n",
    "    age = age_preds[0].argmax()\n",
    "#     print(\"Age Range: \" + age)\n",
    "    return age , gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_net, gender_net = initialize_caffe_models()\n",
    "file = '../face_generator/celebA/img_align_celeba/img_align_celeba/000001.jpg'\n",
    "age_gender_of_face(age_net,gender_net,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## race     ethnicity = [\"Asian\",\t\"Black\", \"Hispanic\",\"Indian\",\t\"White\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_model = load_model('run20-model.h5')\n",
    "race_model.load_weights('run20-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_local(file,w,h):\n",
    "    face = cv2.imread(file,cv2.IMREAD_COLOR)\n",
    "    face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "    face =cv2.resize(face, (w,h))\n",
    "    face = np.asarray(face)\n",
    "    face = face.astype('float32')\n",
    "    face /= 255\n",
    "    return np.array(face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>5_o_Clock_Shadow</th>\n",
       "      <th>Arched_Eyebrows</th>\n",
       "      <th>Attractive</th>\n",
       "      <th>Bags_Under_Eyes</th>\n",
       "      <th>Bald</th>\n",
       "      <th>Bangs</th>\n",
       "      <th>Big_Lips</th>\n",
       "      <th>Big_Nose</th>\n",
       "      <th>Black_Hair</th>\n",
       "      <th>...</th>\n",
       "      <th>Sideburns</th>\n",
       "      <th>Smiling</th>\n",
       "      <th>Straight_Hair</th>\n",
       "      <th>Wavy_Hair</th>\n",
       "      <th>Wearing_Earrings</th>\n",
       "      <th>Wearing_Hat</th>\n",
       "      <th>Wearing_Lipstick</th>\n",
       "      <th>Wearing_Necklace</th>\n",
       "      <th>Wearing_Necktie</th>\n",
       "      <th>Young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17151</th>\n",
       "      <td>017152.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160671</th>\n",
       "      <td>160672.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199855</th>\n",
       "      <td>199856.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38729</th>\n",
       "      <td>038730.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82199</th>\n",
       "      <td>082200.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          image_id  5_o_Clock_Shadow  Arched_Eyebrows  Attractive  \\\n",
       "17151   017152.jpg                 0                1           1   \n",
       "160671  160672.jpg                 0                1           1   \n",
       "199855  199856.jpg                 0                0           0   \n",
       "38729   038730.jpg                 0                0           0   \n",
       "82199   082200.jpg                 0                0           1   \n",
       "\n",
       "        Bags_Under_Eyes  Bald  Bangs  Big_Lips  Big_Nose  Black_Hair  ...  \\\n",
       "17151                 0     0      1         1         0           1  ...   \n",
       "160671                0     0      1         0         0           0  ...   \n",
       "199855                0     0      1         0         0           0  ...   \n",
       "38729                 0     0      0         0         1           0  ...   \n",
       "82199                 0     0      0         0         0           1  ...   \n",
       "\n",
       "        Sideburns  Smiling  Straight_Hair  Wavy_Hair  Wearing_Earrings  \\\n",
       "17151           0        0              0          1                 0   \n",
       "160671          0        1              1          0                 1   \n",
       "199855          0        1              1          0                 0   \n",
       "38729           0        0              1          0                 0   \n",
       "82199           0        1              0          0                 0   \n",
       "\n",
       "        Wearing_Hat  Wearing_Lipstick  Wearing_Necklace  Wearing_Necktie  \\\n",
       "17151             0                 1                 1                0   \n",
       "160671            0                 1                 1                0   \n",
       "199855            0                 1                 1                0   \n",
       "38729             0                 0                 0                0   \n",
       "82199             0                 1                 0                0   \n",
       "\n",
       "        Young  \n",
       "17151       1  \n",
       "160671      0  \n",
       "199855      0  \n",
       "38729       0  \n",
       "82199       1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv('celebA/list_attr_celeba.csv')\n",
    "data1 = data1.sample(frac = 1)[:200]\n",
    "data1 = data1.replace(-1,0)\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:43<00:00,  4.59it/s]\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'age':[],\n",
    "    'gender':[],\n",
    "    'race':[]\n",
    "}\n",
    "# race_model = load_model('model_3/final_cnn_race_model_checkpoint.tf')\n",
    "for image in tqdm(data1['image_id']):\n",
    "    temp = image\n",
    "    file = 'celebA/img_align_celeba/img_align_celeba/'+image\n",
    "    image = get_data_from_local(file,200,200)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    age , gender = age_gender_of_face(age_net,gender_net,file)\n",
    "    data['age'].append(age)\n",
    "    data['gender'].append(gender)\n",
    "    data['race'].append(race_model.predict(np.expand_dims(get_data_from_local(file,64,64),axis=0)).argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_id', '5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive',\n",
       "       'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose',\n",
       "       'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', 'Bushy_Eyebrows',\n",
       "       'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair',\n",
       "       'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open',\n",
       "       'Mustache', 'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin',\n",
       "       'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns',\n",
       "       'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings',\n",
       "       'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace',\n",
       "       'Wearing_Necktie', 'Young'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['age'] = data['age']\n",
    "data1['gender'] = data['gender']\n",
    "data1['race'] = data['race'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data2 = pd.get_dummies(data=data1,columns=['age','gender','race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_id', '5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive',\n",
      "       'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose',\n",
      "       'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', 'Bushy_Eyebrows',\n",
      "       'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair',\n",
      "       'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open',\n",
      "       'Mustache', 'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin',\n",
      "       'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns',\n",
      "       'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings',\n",
      "       'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace',\n",
      "       'Wearing_Necktie', 'Young', 'age_0', 'age_1', 'age_2', 'age_3', 'age_4',\n",
      "       'age_5', 'age_6', 'age_7', 'gender_0', 'gender_1', 'race_0', 'race_1',\n",
      "       'race_2', 'race_3', 'race_4'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data2.columns)\n",
    "len(data2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_csv('decode_datasest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_dataset_(\n",
    "    file_path,\n",
    "    image_per_batch,\n",
    "    start_row,\n",
    "    ):\n",
    "    df = pd.read_csv(file_path)[start_row:start_row+image_per_batch]\n",
    "    df = df.drop('Unnamed: 0',axis=1)\n",
    "\n",
    "    y = get_data_from_local(df)\n",
    "    x = df.drop('image_id',axis=1)\n",
    "    \n",
    "    x = x.astype('float64')\n",
    "        \n",
    "    return x.values , y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_local(X_train):\n",
    "    X_data =[]\n",
    "    for file in tqdm(X_train['image_id']):\n",
    "        file = 'celebA/img_align_celeba/img_align_celeba/' + file\n",
    "        face = cv2.imread(file,cv2.IMREAD_COLOR)\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "        face =cv2.resize(face, (150,150))\n",
    "        face = np.asarray(face)\n",
    "        face = face.astype('float32')\n",
    "        face /= 255\n",
    "        X_data.append(face)\n",
    "    return np.array(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c_a_e = load_model('decoder_cnn_50.tf/')\n",
    "c_a_e.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_a_e.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(\n",
    "    start_row,\n",
    "    number_of_labels,\n",
    "    file_path,\n",
    "    image_per_batch,\n",
    "    max_limit,\n",
    "    path_of_model\n",
    "):\n",
    "\n",
    "    checkpoint = ModelCheckpoint(filepath=path_of_model,\n",
    "                             monitor='val_accuracy',\n",
    "                             save_format='tf',\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             verbose=1\n",
    "                            )\n",
    "    early_stopping_monitor = EarlyStopping(patience=4,verbose=1) \n",
    "    \n",
    "    \n",
    "    for x in range(start_row,max_limit,image_per_batch):\n",
    "        \n",
    "        print()\n",
    "        print('**********{} -- {} out of {}************'.format(x,x+image_per_batch,max_limit))\n",
    "        print()\n",
    "    \n",
    "        X_train , y_train   =   training_dataset_(\n",
    "                        file_path = file_path,\n",
    "                        start_row = x,\n",
    "                        image_per_batch = image_per_batch\n",
    "        )\n",
    "                                    \n",
    "        F_mnist = c_a_e.fit(X_train,y_train,\n",
    "                            shuffle=True,\n",
    "                            epochs=30,\n",
    "                            validation_split=0.2,\n",
    "                            batch_size=64,\n",
    "                            callbacks=[checkpoint,early_stopping_monitor]\n",
    "       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training(\n",
    "    start_row = 0,\n",
    "    number_of_labels = 3,\n",
    "    file_path = 'decode_datasest.csv',\n",
    "    image_per_batch = 500,\n",
    "    max_limit = 500,\n",
    "    path_of_model = 'final_dec_cnn_checkpoint.tf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
