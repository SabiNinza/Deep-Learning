{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_local(file):\n",
    "    face = cv2.imread(file,cv2.IMREAD_COLOR)\n",
    "    face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "    face =cv2.resize(face, (200,200))\n",
    "    face = np.asarray(face)\n",
    "    face = face.astype('float32')\n",
    "    face /= 255\n",
    "    return np.array(face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>5_o_Clock_Shadow</th>\n",
       "      <th>Arched_Eyebrows</th>\n",
       "      <th>Attractive</th>\n",
       "      <th>Bags_Under_Eyes</th>\n",
       "      <th>Bald</th>\n",
       "      <th>Bangs</th>\n",
       "      <th>Big_Lips</th>\n",
       "      <th>Big_Nose</th>\n",
       "      <th>Black_Hair</th>\n",
       "      <th>...</th>\n",
       "      <th>Sideburns</th>\n",
       "      <th>Smiling</th>\n",
       "      <th>Straight_Hair</th>\n",
       "      <th>Wavy_Hair</th>\n",
       "      <th>Wearing_Earrings</th>\n",
       "      <th>Wearing_Hat</th>\n",
       "      <th>Wearing_Lipstick</th>\n",
       "      <th>Wearing_Necklace</th>\n",
       "      <th>Wearing_Necktie</th>\n",
       "      <th>Young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id  5_o_Clock_Shadow  Arched_Eyebrows  Attractive  Bags_Under_Eyes  \\\n",
       "0  000001.jpg                 0                1           1                0   \n",
       "1  000002.jpg                 0                0           0                1   \n",
       "2  000003.jpg                 0                0           0                0   \n",
       "3  000004.jpg                 0                0           1                0   \n",
       "4  000005.jpg                 0                1           1                0   \n",
       "\n",
       "   Bald  Bangs  Big_Lips  Big_Nose  Black_Hair  ...  Sideburns  Smiling  \\\n",
       "0     0      0         0         0           0  ...          0        1   \n",
       "1     0      0         0         1           0  ...          0        1   \n",
       "2     0      0         1         0           0  ...          0        0   \n",
       "3     0      0         0         0           0  ...          0        0   \n",
       "4     0      0         1         0           0  ...          0        0   \n",
       "\n",
       "   Straight_Hair  Wavy_Hair  Wearing_Earrings  Wearing_Hat  Wearing_Lipstick  \\\n",
       "0              1          0                 1            0                 1   \n",
       "1              0          0                 0            0                 0   \n",
       "2              0          1                 0            0                 0   \n",
       "3              1          0                 1            0                 1   \n",
       "4              0          0                 0            0                 1   \n",
       "\n",
       "   Wearing_Necklace  Wearing_Necktie  Young  \n",
       "0                 0                0      1  \n",
       "1                 0                0      1  \n",
       "2                 0                0      1  \n",
       "3                 1                0      1  \n",
       "4                 0                0      1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv('celebA/list_attr_celeba.csv')[:5000]\n",
    "data1 = data1.replace(-1,0)\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [15:38<00:00,  5.33it/s]\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'age':[],\n",
    "    'gender':[],\n",
    "    'race':[]\n",
    "}\n",
    "age_model = load_model('model_3/final_cnn_age_model_checkpoint.tf')\n",
    "gender_model = load_model('model_3/final_cnn_gender_model_checkpoint.tf')\n",
    "race_model = load_model('model_3/final_cnn_race_model_checkpoint.tf')\n",
    "for image in tqdm(data1['image_id']):\n",
    "    temp = image\n",
    "    image = get_data_from_local('celebA/img_align_celeba/img_align_celeba/'+image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    data['age'].append(age_model.predict(image).argmax())\n",
    "    data['gender'].append(gender_model.predict(image).argmax())\n",
    "    data['race'].append(race_model.predict(image).argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_id', '5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive',\n",
       "       'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose',\n",
       "       'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', 'Bushy_Eyebrows',\n",
       "       'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair',\n",
       "       'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open',\n",
       "       'Mustache', 'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin',\n",
       "       'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns',\n",
       "       'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings',\n",
       "       'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace',\n",
       "       'Wearing_Necktie', 'Young'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['age'] = data['age']\n",
    "data1['gender'] = data['gender']\n",
    "data1['race'] = data['race'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1 = data1.drop(columns=['Wearing_Lipstick','Wavy_Hair','Wearing_Earrings','Wearing_Hat','Wearing_Necktie','Young','Mustache','High_Cheekbones','Mouth_Slightly_Open','Goatee'])\n",
    "# len(data1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.get_dummies(data=data1,columns=['age','gender','race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_id', '5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive',\n",
      "       'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose',\n",
      "       'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', 'Bushy_Eyebrows',\n",
      "       'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair',\n",
      "       'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open',\n",
      "       'Mustache', 'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin',\n",
      "       'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns',\n",
      "       'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings',\n",
      "       'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace',\n",
      "       'Wearing_Necktie', 'Young', 'age_0', 'age_3', 'age_4', 'gender_0',\n",
      "       'gender_1', 'race_0', 'race_1'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data2.columns)\n",
    "len(data2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['age_1'] = np.zeros(len(data1))\n",
    "data2['age_2'] = np.zeros(len(data1))\n",
    "data2['age_5'] = np.zeros(len(data1))\n",
    "data2['age_6'] = np.zeros(len(data1))\n",
    "data2['age_7'] = np.zeros(len(data1))\n",
    "data2['race_2'] = np.zeros(len(data1))\n",
    "data2['race_3'] = np.zeros(len(data1))\n",
    "data2['race_4'] = np.zeros(len(data1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_csv('decode_datasest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping \n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_dataset_(\n",
    "    file_path,\n",
    "    image_per_batch,\n",
    "    start_row,\n",
    "    ):\n",
    "    df = pd.read_csv(file_path)[start_row:start_row+image_per_batch]\n",
    "    df = df.drop('Unnamed: 0',axis=1)\n",
    "\n",
    "    y = get_data_from_local(df)\n",
    "    x = df.drop('image_id',axis=1)\n",
    "    \n",
    "    x = x.astype('float64')\n",
    "        \n",
    "    return x.values , y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_local(X_train):\n",
    "    X_data =[]\n",
    "    for file in tqdm(X_train['image_id']):\n",
    "        file = 'celebA/img_align_celeba/img_align_celeba/' + file\n",
    "        face = cv2.imread(file,cv2.IMREAD_COLOR)\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "        face =cv2.resize(face, (150,150))\n",
    "        face = np.asarray(face)\n",
    "        face = face.astype('float32')\n",
    "        face /= 255\n",
    "        X_data.append(face)\n",
    "    return np.array(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "c_a_e = load_model('decoder_cnn_50.tf/')\n",
    "c_a_e.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 30)]              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 900)               27900     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 10, 10, 9)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 20, 20, 9)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 22, 22, 9)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 22, 16)        1312      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 50, 50, 3)         867       \n",
      "=================================================================\n",
      "Total params: 34,719\n",
      "Trainable params: 34,719\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "c_a_e.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(\n",
    "    start_row,\n",
    "    number_of_labels,\n",
    "    file_path,\n",
    "    image_per_batch,\n",
    "    max_limit,\n",
    "    path_of_model\n",
    "):\n",
    "\n",
    "    checkpoint = ModelCheckpoint(filepath=path_of_model,\n",
    "                             monitor='val_accuracy',\n",
    "                             save_format='tf',\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             verbose=1\n",
    "                            )\n",
    "    early_stopping_monitor = EarlyStopping(patience=4,verbose=1) \n",
    "    \n",
    "    \n",
    "    for x in range(start_row,max_limit,image_per_batch):\n",
    "        \n",
    "        print()\n",
    "        print('**********{} -- {} out of {}************'.format(x,x+image_per_batch,max_limit))\n",
    "        print()\n",
    "    \n",
    "        X_train , y_train   =   training_dataset_(\n",
    "                        file_path = file_path,\n",
    "                        start_row = x,\n",
    "                        image_per_batch = image_per_batch\n",
    "        )\n",
    "                                    \n",
    "        F_mnist = c_a_e.fit(X_train,y_train,\n",
    "                            shuffle=True,\n",
    "                            epochs=30,\n",
    "                            validation_split=0.2,\n",
    "                            batch_size=64,\n",
    "                            callbacks=[checkpoint,early_stopping_monitor]\n",
    "       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training(\n",
    "    start_row = 0,\n",
    "    number_of_labels = 3,\n",
    "    file_path = 'decode_datasest.csv',\n",
    "    image_per_batch = 500,\n",
    "    max_limit = 500,\n",
    "    path_of_model = 'final_dec_cnn_checkpoint.tf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
