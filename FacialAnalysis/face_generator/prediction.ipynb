{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tqdm import tqdm\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "from keras.callbacks import EarlyStopping \n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_dataset_(\n",
    "    file_path,\n",
    "    image_per_batch,\n",
    "    start_row,\n",
    "    ):\n",
    "    df = pd.read_csv(file_path)[start_row:start_row+image_per_batch]\n",
    "    \n",
    "    df = df.drop('Unnamed: 0',axis=1)\n",
    "    \n",
    "    y = get_data_from_local(df)\n",
    "    x = df.drop('image',axis=1)\n",
    "    x = x.values\n",
    "    \n",
    "    return x , y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_local(X_train):\n",
    "    X_data =[]\n",
    "    for file in tqdm(X_train['image']):\n",
    "        face = cv2.imread(file,cv2.IMREAD_COLOR)\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "        face =cv2.resize(face, (200,200))\n",
    "#         face = np.expand_dims(face, axis=2)\n",
    "        face = np.asarray(face)\n",
    "        face = face.astype('float32')\n",
    "        face /= 255\n",
    "        X_data.append(face)\n",
    "    return np.array(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D , MaxPool2D ,ZeroPadding2D , UpSampling2D ,Reshape, Input ,Dense, Activation,Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "\n",
    "def model(number_of_label):\n",
    "    inp = Input(shape = (number_of_label,))\n",
    "    \n",
    "    fc1 = Dense(500,activation=\"sigmoid\")(inp)\n",
    "    \n",
    "    fc2 = Dense(2000,activation=\"sigmoid\")(fc1)\n",
    "    \n",
    "    fc3 = Dense(4000,activation=\"sigmoid\")(fc2)\n",
    "\n",
    "    fc4 = Dense(8836,activation=\"sigmoid\")(fc3)\n",
    "\n",
    "    res1 = Reshape((47,47,4))(fc4)\n",
    "    zrp1 = ZeroPadding2D((1,1))(res1)\n",
    "\n",
    "    conv4 = Conv2D(16,(3,3),padding=\"same\" , activation =\"relu\")(zrp1)\n",
    "    ups1 = UpSampling2D((2,2))(conv4)\n",
    "    \n",
    "    conv8 = Conv2D(16,(3,3),padding=\"same\" , activation =\"relu\")(ups1)\n",
    "    ups7 = UpSampling2D((2,2))(conv8)\n",
    "\n",
    "    zrp2 = ZeroPadding2D((1,1))(ups7)\n",
    "    conv5 = Conv2D(32,(3,3),padding=\"same\" , activation =\"relu\")(zrp2)\n",
    "\n",
    "    zrp3 = ZeroPadding2D((1,1))(conv5)\n",
    "    conv6 = Conv2D(3,(3,3),padding=\"same\" , activation=\"relu\")(zrp3)\n",
    "    c_a_e = Model(inputs=inp, outputs=conv6)\n",
    "    c_a_e.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    c_a_e.summary()\n",
    "    return c_a_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(\n",
    "    start_row,\n",
    "    number_of_labels,\n",
    "    file_path,\n",
    "    image_per_batch,\n",
    "    max_limit,\n",
    "    path_of_model\n",
    "):\n",
    "\n",
    "    checkpoint = ModelCheckpoint(filepath=path_of_model,\n",
    "                             monitor='val_accuracy',\n",
    "                             save_format='tf',\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             verbose=1\n",
    "                            )\n",
    "    early_stopping_monitor = EarlyStopping(patience=2,verbose=1) \n",
    "    \n",
    "    for x in range(start_row,max_limit,image_per_batch):\n",
    "        \n",
    "        print()\n",
    "        print('**********{} -- {} out of {}************'.format(x,x+image_per_batch,max_limit))\n",
    "        print()\n",
    "    \n",
    "        X_train , y_train   =   training_dataset_(\n",
    "                        file_path = file_path,\n",
    "                        start_row = x,\n",
    "                        image_per_batch = image_per_batch,\n",
    "        )\n",
    "        \n",
    "        if x != 0:\n",
    "            final_cnn = load_model(path_of_model)\n",
    "        else:\n",
    "            final_cnn = model(number_of_labels)\n",
    "            \n",
    "        try:\n",
    "            final_cnn_history = final_cnn.fit(x=X_train,\n",
    "                                          y=y_train,\n",
    "                                          batch_size=64,\n",
    "                                          validation_split=0.5,\n",
    "                                          epochs=10,\n",
    "                                          callbacks=[checkpoint,early_stopping_monitor],\n",
    "                                          shuffle=False    # shuffle=False to reduce randomness and increase reproducibility\n",
    "                                         )\n",
    "        except:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/600 [00:00<00:08, 68.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********0 -- 600 out of 1000************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:06<00:00, 89.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2000)              1002000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4000)              8004000   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8836)              35352836  \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 47, 47, 4)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 49, 49, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 49, 49, 16)        592       \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 98, 98, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 98, 98, 16)        2320      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 196, 196, 16)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 198, 198, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 198, 198, 32)      4640      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 200, 200, 3)       867       \n",
      "=================================================================\n",
      "Total params: 44,369,255\n",
      "Trainable params: 44,369,255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.1357 - accuracy: 0.4570\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66849, saving model to final_cnn_checkpoint.tf\n",
      "WARNING:tensorflow:From /home/falcon-puneet/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/falcon-puneet/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: final_cnn_checkpoint.tf/assets\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.1357 - accuracy: 0.4570 - val_loss: 0.0940 - val_accuracy: 0.6685\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 0.5012\n",
      "Epoch 00002: val_accuracy did not improve from 0.66849\n",
      "5/5 [==============================] - 21s 4s/step - loss: 0.0891 - accuracy: 0.5012 - val_loss: 0.0878 - val_accuracy: 0.5175\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.6121\n",
      "Epoch 00003: val_accuracy improved from 0.66849 to 0.70303, saving model to final_cnn_checkpoint.tf\n",
      "INFO:tensorflow:Assets written to: final_cnn_checkpoint.tf/assets\n",
      "5/5 [==============================] - 33s 7s/step - loss: 0.0821 - accuracy: 0.6121 - val_loss: 0.0821 - val_accuracy: 0.7030\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.7207\n",
      "Epoch 00004: val_accuracy improved from 0.70303 to 0.72889, saving model to final_cnn_checkpoint.tf\n",
      "INFO:tensorflow:Assets written to: final_cnn_checkpoint.tf/assets\n",
      "5/5 [==============================] - 32s 6s/step - loss: 0.0798 - accuracy: 0.7207 - val_loss: 0.0784 - val_accuracy: 0.7289\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.7209\n",
      "Epoch 00005: val_accuracy did not improve from 0.72889\n",
      "5/5 [==============================] - 21s 4s/step - loss: 0.0770 - accuracy: 0.7209 - val_loss: 0.0770 - val_accuracy: 0.6929\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0762 - accuracy: 0.6964\n",
      "Epoch 00006: val_accuracy did not improve from 0.72889\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.0762 - accuracy: 0.6964 - val_loss: 0.0752 - val_accuracy: 0.7176\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.7300\n",
      "Epoch 00007: val_accuracy improved from 0.72889 to 0.74028, saving model to final_cnn_checkpoint.tf\n",
      "INFO:tensorflow:Assets written to: final_cnn_checkpoint.tf/assets\n",
      "5/5 [==============================] - 33s 7s/step - loss: 0.0745 - accuracy: 0.7300 - val_loss: 0.0745 - val_accuracy: 0.7403\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.7442\n",
      "Epoch 00008: val_accuracy improved from 0.74028 to 0.74073, saving model to final_cnn_checkpoint.tf\n",
      "INFO:tensorflow:Assets written to: final_cnn_checkpoint.tf/assets\n",
      "5/5 [==============================] - 32s 6s/step - loss: 0.0737 - accuracy: 0.7442 - val_loss: 0.0736 - val_accuracy: 0.7407\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.7424\n",
      "Epoch 00009: val_accuracy did not improve from 0.74073\n",
      "5/5 [==============================] - 21s 4s/step - loss: 0.0729 - accuracy: 0.7424 - val_loss: 0.0730 - val_accuracy: 0.7386\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.7438\n",
      "Epoch 00010: val_accuracy improved from 0.74073 to 0.74504, saving model to final_cnn_checkpoint.tf\n",
      "INFO:tensorflow:Assets written to: final_cnn_checkpoint.tf/assets\n",
      "5/5 [==============================] - 33s 7s/step - loss: 0.0724 - accuracy: 0.7438 - val_loss: 0.0724 - val_accuracy: 0.7450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 9/481 [00:00<00:05, 89.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********600 -- 1200 out of 1000************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 481/481 [00:05<00:00, 89.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.7589\n",
      "Epoch 00001: val_accuracy improved from 0.74504 to 0.75012, saving model to final_cnn_checkpoint.tf\n",
      "INFO:tensorflow:Assets written to: final_cnn_checkpoint.tf/assets\n",
      "4/4 [==============================] - 28s 7s/step - loss: 0.0777 - accuracy: 0.7589 - val_loss: 0.0742 - val_accuracy: 0.7501\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.7505\n",
      "Epoch 00002: val_accuracy did not improve from 0.75012\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0741 - accuracy: 0.7505 - val_loss: 0.0730 - val_accuracy: 0.7317\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 0.7481\n",
      "Epoch 00003: val_accuracy did not improve from 0.75012\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0740 - accuracy: 0.7481 - val_loss: 0.0717 - val_accuracy: 0.7487\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.7597\n",
      "Epoch 00004: val_accuracy did not improve from 0.75012\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0729 - accuracy: 0.7597 - val_loss: 0.0709 - val_accuracy: 0.7475\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.7522\n",
      "Epoch 00005: val_accuracy did not improve from 0.75012\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0727 - accuracy: 0.7522 - val_loss: 0.0705 - val_accuracy: 0.7329\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.7461\n",
      "Epoch 00006: val_accuracy improved from 0.75012 to 0.75374, saving model to final_cnn_checkpoint.tf\n",
      "INFO:tensorflow:Assets written to: final_cnn_checkpoint.tf/assets\n",
      "4/4 [==============================] - 29s 7s/step - loss: 0.0724 - accuracy: 0.7461 - val_loss: 0.0702 - val_accuracy: 0.7537\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0720 - accuracy: 0.7662\n",
      "Epoch 00007: val_accuracy improved from 0.75374 to 0.75586, saving model to final_cnn_checkpoint.tf\n",
      "INFO:tensorflow:Assets written to: final_cnn_checkpoint.tf/assets\n",
      "4/4 [==============================] - 27s 7s/step - loss: 0.0720 - accuracy: 0.7662 - val_loss: 0.0702 - val_accuracy: 0.7559\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.7583\n",
      "Epoch 00008: val_accuracy did not improve from 0.75586\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.0719 - accuracy: 0.7583 - val_loss: 0.0701 - val_accuracy: 0.7381\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 0.7507\n",
      "Epoch 00009: val_accuracy did not improve from 0.75586\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0717 - accuracy: 0.7507 - val_loss: 0.0699 - val_accuracy: 0.7530\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 0.7653\n",
      "Epoch 00010: val_accuracy did not improve from 0.75586\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0717 - accuracy: 0.7653 - val_loss: 0.0698 - val_accuracy: 0.7549\n"
     ]
    }
   ],
   "source": [
    "training(\n",
    "    start_row = 0,\n",
    "    number_of_labels = 3,\n",
    "    file_path = 'main_dataset.csv',\n",
    "    image_per_batch = 600,\n",
    "    max_limit = 1000,\n",
    "    path_of_model = 'final_cnn_checkpoint.tf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
